{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eb73bd5",
   "metadata": {},
   "source": [
    "# Exploration et Modélisation pour le Score de Crédit Home Credit\n",
    "\n",
    "Ce notebook présente l'exploration des données et la modélisation pour le système de scoring de crédit de Home Credit.\n",
    "\n",
    "**Note**: Ce projet est basé sur le modèle de [Home Credit Default Risk par rakshithvasudev](https://github.com/rakshithvasudev/Home-Credit-Default-Risk) que nous allons adapter et faire évoluer pour notre cas d'utilisation.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "De nombreuses personnes ont des difficultés à obtenir des prêts en raison d'antécédents de crédit insuffisants ou inexistants. Malheureusement, cette population est souvent exploitée par des prêteurs peu scrupuleux.\n",
    "\n",
    "Home Credit s'efforce d'élargir l'inclusion financière pour la population non bancarisée en offrant une expérience d'emprunt positive et sûre. Pour s'assurer que cette population mal desservie vive une expérience de prêt positive, Home Credit utilise diverses données alternatives - y compris des informations sur les télécommunications et les transactions - pour prédire la capacité de remboursement de ses clients.\n",
    "\n",
    "L'objectif de ce projet est d'utiliser les données historiques des demandes de prêt pour prédire si un candidat sera en mesure de rembourser un prêt ou non."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd5dd62",
   "metadata": {},
   "source": [
    "## Téléchargement des données depuis Kaggle\n",
    "\n",
    "Pour ce projet, nous utilisons le dataset de la compétition Kaggle 'Home Credit Default Risk'. Voici comment télécharger et préparer les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "faac77b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Installation de l'API Kaggle si nécessaire\n",
    "!pip install -q kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7384b7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier d'API Kaggle trouvé!\n"
     ]
    }
   ],
   "source": [
    "# Configuration des identifiants Kaggle\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Créer le dossier Kaggle si nécessaire\n",
    "os.makedirs(os.path.expanduser(\"~/.kaggle\"), exist_ok=True)\n",
    "\n",
    "# Vérifier si le fichier d'API Kaggle existe déjà\n",
    "kaggle_path = os.path.expanduser(\"~/.kaggle/kaggle.json\")\n",
    "if not os.path.exists(kaggle_path):\n",
    "    print(\"Vous devez configurer votre API Kaggle. Deux options:\")\n",
    "    print(\"1. Téléchargez kaggle.json depuis votre compte Kaggle (My Account > API) et placez-le dans ~/.kaggle/\")\n",
    "    print(\"2. Ou entrez vos identifiants ci-dessous (ils ne seront pas affichés):\")\n",
    "    \n",
    "    import getpass\n",
    "    username = input(\"Nom d'utilisateur Kaggle: \")\n",
    "    key = getpass.getpass(\"Clé API Kaggle: \")\n",
    "    \n",
    "    # Sauvegarder les identifiants\n",
    "    with open(kaggle_path, 'w') as f:\n",
    "        json.dump({\"username\": username, \"key\": key}, f)\n",
    "    \n",
    "    # Protéger le fichier\n",
    "    os.chmod(kaggle_path, 0o600)\n",
    "    print(\"Identifiants Kaggle sauvegardés avec succès!\")\n",
    "else:\n",
    "    print(\"Fichier d'API Kaggle trouvé!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5105154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les données sont déjà téléchargées et extraites.\n",
      "\n",
      "Fichiers de données disponibles:\n",
      " - application_test.csv (25.34 MB)\n",
      " - application_train.csv (158.44 MB)\n",
      " - application_test.csv (25.34 MB)\n",
      " - application_train.csv (158.44 MB)\n"
     ]
    }
   ],
   "source": [
    "# Définir le répertoire de données et télécharger le dataset si nécessaire\n",
    "DATA_PATH = \"../data/\"\n",
    "os.makedirs(DATA_PATH, exist_ok=True)\n",
    "\n",
    "# Vérifier si les données sont déjà téléchargées\n",
    "if not os.path.exists(os.path.join(DATA_PATH, \"application_train.csv\")):\n",
    "    print(\"Téléchargement du dataset Home Credit Default Risk...\")\n",
    "    # Télécharger les données depuis Kaggle\n",
    "    !kaggle competitions download -c home-credit-default-risk -p {DATA_PATH}\n",
    "    \n",
    "    # Extraire les fichiers zip\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile(os.path.join(DATA_PATH, 'home-credit-default-risk.zip'), 'r') as zip_ref:\n",
    "        zip_ref.extractall(DATA_PATH)\n",
    "        \n",
    "    print(\"Données téléchargées et extraites avec succès!\")\n",
    "else:\n",
    "    print(\"Les données sont déjà téléchargées et extraites.\")\n",
    "\n",
    "# Afficher les fichiers de données disponibles\n",
    "print(\"\\nFichiers de données disponibles:\")\n",
    "for file in sorted(os.listdir(DATA_PATH)):\n",
    "    if file.endswith('.csv'):\n",
    "        file_path = os.path.join(DATA_PATH, file)\n",
    "        size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
    "        print(f\" - {file} ({size_mb:.2f} MB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe9d3f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structure du fichier application_train.csv:\n",
      "Shape: (5, 122)\n",
      "Shape: (5, 122)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>NAME_TYPE_SUITE</th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_EDUCATION_TYPE</th>\n",
       "      <th>NAME_FAMILY_STATUS</th>\n",
       "      <th>NAME_HOUSING_TYPE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>OWN_CAR_AGE</th>\n",
       "      <th>FLAG_MOBIL</th>\n",
       "      <th>FLAG_EMP_PHONE</th>\n",
       "      <th>FLAG_WORK_PHONE</th>\n",
       "      <th>FLAG_CONT_MOBILE</th>\n",
       "      <th>FLAG_PHONE</th>\n",
       "      <th>FLAG_EMAIL</th>\n",
       "      <th>OCCUPATION_TYPE</th>\n",
       "      <th>CNT_FAM_MEMBERS</th>\n",
       "      <th>REGION_RATING_CLIENT</th>\n",
       "      <th>REGION_RATING_CLIENT_W_CITY</th>\n",
       "      <th>WEEKDAY_APPR_PROCESS_START</th>\n",
       "      <th>HOUR_APPR_PROCESS_START</th>\n",
       "      <th>REG_REGION_NOT_LIVE_REGION</th>\n",
       "      <th>REG_REGION_NOT_WORK_REGION</th>\n",
       "      <th>LIVE_REGION_NOT_WORK_REGION</th>\n",
       "      <th>REG_CITY_NOT_LIVE_CITY</th>\n",
       "      <th>REG_CITY_NOT_WORK_CITY</th>\n",
       "      <th>LIVE_CITY_NOT_WORK_CITY</th>\n",
       "      <th>ORGANIZATION_TYPE</th>\n",
       "      <th>EXT_SOURCE_1</th>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "      <th>EXT_SOURCE_3</th>\n",
       "      <th>APARTMENTS_AVG</th>\n",
       "      <th>BASEMENTAREA_AVG</th>\n",
       "      <th>YEARS_BEGINEXPLUATATION_AVG</th>\n",
       "      <th>YEARS_BUILD_AVG</th>\n",
       "      <th>COMMONAREA_AVG</th>\n",
       "      <th>ELEVATORS_AVG</th>\n",
       "      <th>...</th>\n",
       "      <th>APARTMENTS_MEDI</th>\n",
       "      <th>BASEMENTAREA_MEDI</th>\n",
       "      <th>YEARS_BEGINEXPLUATATION_MEDI</th>\n",
       "      <th>YEARS_BUILD_MEDI</th>\n",
       "      <th>COMMONAREA_MEDI</th>\n",
       "      <th>ELEVATORS_MEDI</th>\n",
       "      <th>ENTRANCES_MEDI</th>\n",
       "      <th>FLOORSMAX_MEDI</th>\n",
       "      <th>FLOORSMIN_MEDI</th>\n",
       "      <th>LANDAREA_MEDI</th>\n",
       "      <th>LIVINGAPARTMENTS_MEDI</th>\n",
       "      <th>LIVINGAREA_MEDI</th>\n",
       "      <th>NONLIVINGAPARTMENTS_MEDI</th>\n",
       "      <th>NONLIVINGAREA_MEDI</th>\n",
       "      <th>FONDKAPREMONT_MODE</th>\n",
       "      <th>HOUSETYPE_MODE</th>\n",
       "      <th>TOTALAREA_MODE</th>\n",
       "      <th>WALLSMATERIAL_MODE</th>\n",
       "      <th>EMERGENCYSTATE_MODE</th>\n",
       "      <th>OBS_30_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>DEF_30_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>OBS_60_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>DEF_60_CNT_SOCIAL_CIRCLE</th>\n",
       "      <th>DAYS_LAST_PHONE_CHANGE</th>\n",
       "      <th>FLAG_DOCUMENT_2</th>\n",
       "      <th>FLAG_DOCUMENT_3</th>\n",
       "      <th>FLAG_DOCUMENT_4</th>\n",
       "      <th>FLAG_DOCUMENT_5</th>\n",
       "      <th>FLAG_DOCUMENT_6</th>\n",
       "      <th>FLAG_DOCUMENT_7</th>\n",
       "      <th>FLAG_DOCUMENT_8</th>\n",
       "      <th>FLAG_DOCUMENT_9</th>\n",
       "      <th>FLAG_DOCUMENT_10</th>\n",
       "      <th>FLAG_DOCUMENT_11</th>\n",
       "      <th>FLAG_DOCUMENT_12</th>\n",
       "      <th>FLAG_DOCUMENT_13</th>\n",
       "      <th>FLAG_DOCUMENT_14</th>\n",
       "      <th>FLAG_DOCUMENT_15</th>\n",
       "      <th>FLAG_DOCUMENT_16</th>\n",
       "      <th>FLAG_DOCUMENT_17</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>351000.0</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>0.018801</td>\n",
       "      <td>-9461</td>\n",
       "      <td>-637</td>\n",
       "      <td>-3648.0</td>\n",
       "      <td>-2120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>WEDNESDAY</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Business Entity Type 3</td>\n",
       "      <td>0.083037</td>\n",
       "      <td>0.262949</td>\n",
       "      <td>0.139376</td>\n",
       "      <td>0.0247</td>\n",
       "      <td>0.0369</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>0.6192</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0369</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>0.6243</td>\n",
       "      <td>0.0144</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0690</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>reg oper account</td>\n",
       "      <td>block of flats</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>Stone, brick</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1134.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>1129500.0</td>\n",
       "      <td>Family</td>\n",
       "      <td>State servant</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>-16765</td>\n",
       "      <td>-1188</td>\n",
       "      <td>-1186.0</td>\n",
       "      <td>-291</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Core staff</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MONDAY</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>School</td>\n",
       "      <td>0.311267</td>\n",
       "      <td>0.622246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0959</td>\n",
       "      <td>0.0529</td>\n",
       "      <td>0.9851</td>\n",
       "      <td>0.7960</td>\n",
       "      <td>0.0605</td>\n",
       "      <td>0.08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0968</td>\n",
       "      <td>0.0529</td>\n",
       "      <td>0.9851</td>\n",
       "      <td>0.7987</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.2917</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0787</td>\n",
       "      <td>0.0558</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.01</td>\n",
       "      <td>reg oper account</td>\n",
       "      <td>block of flats</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>Block</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-828.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>0.010032</td>\n",
       "      <td>-19046</td>\n",
       "      <td>-225</td>\n",
       "      <td>-4260.0</td>\n",
       "      <td>-2531</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>MONDAY</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Government</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.555912</td>\n",
       "      <td>0.729567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-815.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>297000.0</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>0.008019</td>\n",
       "      <td>-19005</td>\n",
       "      <td>-3039</td>\n",
       "      <td>-9833.0</td>\n",
       "      <td>-2437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>WEDNESDAY</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Business Entity Type 3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.650442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-617.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>Unaccompanied</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Single / not married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>0.028663</td>\n",
       "      <td>-19932</td>\n",
       "      <td>-3038</td>\n",
       "      <td>-4311.0</td>\n",
       "      <td>-3458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Core staff</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>THURSDAY</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Religion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.322738</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1106.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "0      100002       1         Cash loans           M            N   \n",
       "1      100003       0         Cash loans           F            N   \n",
       "2      100004       0    Revolving loans           M            Y   \n",
       "3      100006       0         Cash loans           F            N   \n",
       "4      100007       0         Cash loans           M            N   \n",
       "\n",
       "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0               Y             0          202500.0    406597.5      24700.5   \n",
       "1               N             0          270000.0   1293502.5      35698.5   \n",
       "2               Y             0           67500.0    135000.0       6750.0   \n",
       "3               Y             0          135000.0    312682.5      29686.5   \n",
       "4               Y             0          121500.0    513000.0      21865.5   \n",
       "\n",
       "   AMT_GOODS_PRICE NAME_TYPE_SUITE NAME_INCOME_TYPE  \\\n",
       "0         351000.0   Unaccompanied          Working   \n",
       "1        1129500.0          Family    State servant   \n",
       "2         135000.0   Unaccompanied          Working   \n",
       "3         297000.0   Unaccompanied          Working   \n",
       "4         513000.0   Unaccompanied          Working   \n",
       "\n",
       "             NAME_EDUCATION_TYPE    NAME_FAMILY_STATUS  NAME_HOUSING_TYPE  \\\n",
       "0  Secondary / secondary special  Single / not married  House / apartment   \n",
       "1               Higher education               Married  House / apartment   \n",
       "2  Secondary / secondary special  Single / not married  House / apartment   \n",
       "3  Secondary / secondary special        Civil marriage  House / apartment   \n",
       "4  Secondary / secondary special  Single / not married  House / apartment   \n",
       "\n",
       "   REGION_POPULATION_RELATIVE  DAYS_BIRTH  DAYS_EMPLOYED  DAYS_REGISTRATION  \\\n",
       "0                    0.018801       -9461           -637            -3648.0   \n",
       "1                    0.003541      -16765          -1188            -1186.0   \n",
       "2                    0.010032      -19046           -225            -4260.0   \n",
       "3                    0.008019      -19005          -3039            -9833.0   \n",
       "4                    0.028663      -19932          -3038            -4311.0   \n",
       "\n",
       "   DAYS_ID_PUBLISH  OWN_CAR_AGE  FLAG_MOBIL  FLAG_EMP_PHONE  FLAG_WORK_PHONE  \\\n",
       "0            -2120          NaN           1               1                0   \n",
       "1             -291          NaN           1               1                0   \n",
       "2            -2531         26.0           1               1                1   \n",
       "3            -2437          NaN           1               1                0   \n",
       "4            -3458          NaN           1               1                0   \n",
       "\n",
       "   FLAG_CONT_MOBILE  FLAG_PHONE  FLAG_EMAIL OCCUPATION_TYPE  CNT_FAM_MEMBERS  \\\n",
       "0                 1           1           0        Laborers              1.0   \n",
       "1                 1           1           0      Core staff              2.0   \n",
       "2                 1           1           0        Laborers              1.0   \n",
       "3                 1           0           0        Laborers              2.0   \n",
       "4                 1           0           0      Core staff              1.0   \n",
       "\n",
       "   REGION_RATING_CLIENT  REGION_RATING_CLIENT_W_CITY  \\\n",
       "0                     2                            2   \n",
       "1                     1                            1   \n",
       "2                     2                            2   \n",
       "3                     2                            2   \n",
       "4                     2                            2   \n",
       "\n",
       "  WEEKDAY_APPR_PROCESS_START  HOUR_APPR_PROCESS_START  \\\n",
       "0                  WEDNESDAY                       10   \n",
       "1                     MONDAY                       11   \n",
       "2                     MONDAY                        9   \n",
       "3                  WEDNESDAY                       17   \n",
       "4                   THURSDAY                       11   \n",
       "\n",
       "   REG_REGION_NOT_LIVE_REGION  REG_REGION_NOT_WORK_REGION  \\\n",
       "0                           0                           0   \n",
       "1                           0                           0   \n",
       "2                           0                           0   \n",
       "3                           0                           0   \n",
       "4                           0                           0   \n",
       "\n",
       "   LIVE_REGION_NOT_WORK_REGION  REG_CITY_NOT_LIVE_CITY  \\\n",
       "0                            0                       0   \n",
       "1                            0                       0   \n",
       "2                            0                       0   \n",
       "3                            0                       0   \n",
       "4                            0                       0   \n",
       "\n",
       "   REG_CITY_NOT_WORK_CITY  LIVE_CITY_NOT_WORK_CITY       ORGANIZATION_TYPE  \\\n",
       "0                       0                        0  Business Entity Type 3   \n",
       "1                       0                        0                  School   \n",
       "2                       0                        0              Government   \n",
       "3                       0                        0  Business Entity Type 3   \n",
       "4                       1                        1                Religion   \n",
       "\n",
       "   EXT_SOURCE_1  EXT_SOURCE_2  EXT_SOURCE_3  APARTMENTS_AVG  BASEMENTAREA_AVG  \\\n",
       "0      0.083037      0.262949      0.139376          0.0247            0.0369   \n",
       "1      0.311267      0.622246           NaN          0.0959            0.0529   \n",
       "2           NaN      0.555912      0.729567             NaN               NaN   \n",
       "3           NaN      0.650442           NaN             NaN               NaN   \n",
       "4           NaN      0.322738           NaN             NaN               NaN   \n",
       "\n",
       "   YEARS_BEGINEXPLUATATION_AVG  YEARS_BUILD_AVG  COMMONAREA_AVG  \\\n",
       "0                       0.9722           0.6192          0.0143   \n",
       "1                       0.9851           0.7960          0.0605   \n",
       "2                          NaN              NaN             NaN   \n",
       "3                          NaN              NaN             NaN   \n",
       "4                          NaN              NaN             NaN   \n",
       "\n",
       "   ELEVATORS_AVG  ...  APARTMENTS_MEDI  BASEMENTAREA_MEDI  \\\n",
       "0           0.00  ...           0.0250             0.0369   \n",
       "1           0.08  ...           0.0968             0.0529   \n",
       "2            NaN  ...              NaN                NaN   \n",
       "3            NaN  ...              NaN                NaN   \n",
       "4            NaN  ...              NaN                NaN   \n",
       "\n",
       "   YEARS_BEGINEXPLUATATION_MEDI  YEARS_BUILD_MEDI  COMMONAREA_MEDI  \\\n",
       "0                        0.9722            0.6243           0.0144   \n",
       "1                        0.9851            0.7987           0.0608   \n",
       "2                           NaN               NaN              NaN   \n",
       "3                           NaN               NaN              NaN   \n",
       "4                           NaN               NaN              NaN   \n",
       "\n",
       "   ELEVATORS_MEDI  ENTRANCES_MEDI  FLOORSMAX_MEDI  FLOORSMIN_MEDI  \\\n",
       "0            0.00          0.0690          0.0833          0.1250   \n",
       "1            0.08          0.0345          0.2917          0.3333   \n",
       "2             NaN             NaN             NaN             NaN   \n",
       "3             NaN             NaN             NaN             NaN   \n",
       "4             NaN             NaN             NaN             NaN   \n",
       "\n",
       "   LANDAREA_MEDI  LIVINGAPARTMENTS_MEDI  LIVINGAREA_MEDI  \\\n",
       "0         0.0375                 0.0205           0.0193   \n",
       "1         0.0132                 0.0787           0.0558   \n",
       "2            NaN                    NaN              NaN   \n",
       "3            NaN                    NaN              NaN   \n",
       "4            NaN                    NaN              NaN   \n",
       "\n",
       "   NONLIVINGAPARTMENTS_MEDI  NONLIVINGAREA_MEDI  FONDKAPREMONT_MODE  \\\n",
       "0                    0.0000                0.00    reg oper account   \n",
       "1                    0.0039                0.01    reg oper account   \n",
       "2                       NaN                 NaN                 NaN   \n",
       "3                       NaN                 NaN                 NaN   \n",
       "4                       NaN                 NaN                 NaN   \n",
       "\n",
       "   HOUSETYPE_MODE  TOTALAREA_MODE  WALLSMATERIAL_MODE  EMERGENCYSTATE_MODE  \\\n",
       "0  block of flats          0.0149        Stone, brick                   No   \n",
       "1  block of flats          0.0714               Block                   No   \n",
       "2             NaN             NaN                 NaN                  NaN   \n",
       "3             NaN             NaN                 NaN                  NaN   \n",
       "4             NaN             NaN                 NaN                  NaN   \n",
       "\n",
       "   OBS_30_CNT_SOCIAL_CIRCLE  DEF_30_CNT_SOCIAL_CIRCLE  \\\n",
       "0                       2.0                       2.0   \n",
       "1                       1.0                       0.0   \n",
       "2                       0.0                       0.0   \n",
       "3                       2.0                       0.0   \n",
       "4                       0.0                       0.0   \n",
       "\n",
       "   OBS_60_CNT_SOCIAL_CIRCLE  DEF_60_CNT_SOCIAL_CIRCLE  DAYS_LAST_PHONE_CHANGE  \\\n",
       "0                       2.0                       2.0                 -1134.0   \n",
       "1                       1.0                       0.0                  -828.0   \n",
       "2                       0.0                       0.0                  -815.0   \n",
       "3                       2.0                       0.0                  -617.0   \n",
       "4                       0.0                       0.0                 -1106.0   \n",
       "\n",
       "   FLAG_DOCUMENT_2  FLAG_DOCUMENT_3  FLAG_DOCUMENT_4  FLAG_DOCUMENT_5  \\\n",
       "0                0                1                0                0   \n",
       "1                0                1                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                1                0                0   \n",
       "4                0                0                0                0   \n",
       "\n",
       "   FLAG_DOCUMENT_6  FLAG_DOCUMENT_7  FLAG_DOCUMENT_8  FLAG_DOCUMENT_9  \\\n",
       "0                0                0                0                0   \n",
       "1                0                0                0                0   \n",
       "2                0                0                0                0   \n",
       "3                0                0                0                0   \n",
       "4                0                0                1                0   \n",
       "\n",
       "   FLAG_DOCUMENT_10  FLAG_DOCUMENT_11  FLAG_DOCUMENT_12  FLAG_DOCUMENT_13  \\\n",
       "0                 0                 0                 0                 0   \n",
       "1                 0                 0                 0                 0   \n",
       "2                 0                 0                 0                 0   \n",
       "3                 0                 0                 0                 0   \n",
       "4                 0                 0                 0                 0   \n",
       "\n",
       "  FLAG_DOCUMENT_14 FLAG_DOCUMENT_15  FLAG_DOCUMENT_16 FLAG_DOCUMENT_17  \\\n",
       "0                0                0                 0                0   \n",
       "1                0                0                 0                0   \n",
       "2                0                0                 0                0   \n",
       "3                0                0                 0                0   \n",
       "4                0                0                 0                0   \n",
       "\n",
       "  FLAG_DOCUMENT_18  FLAG_DOCUMENT_19  FLAG_DOCUMENT_20  FLAG_DOCUMENT_21  \\\n",
       "0                0                 0                 0                 0   \n",
       "1                0                 0                 0                 0   \n",
       "2                0                 0                 0                 0   \n",
       "3                0                 0                 0                 0   \n",
       "4                0                 0                 0                 0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_HOUR  AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
       "0                         0.0                        0.0   \n",
       "1                         0.0                        0.0   \n",
       "2                         0.0                        0.0   \n",
       "3                         NaN                        NaN   \n",
       "4                         0.0                        0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
       "0                         0.0                        0.0   \n",
       "1                         0.0                        0.0   \n",
       "2                         0.0                        0.0   \n",
       "3                         NaN                        NaN   \n",
       "4                         0.0                        0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "0                        0.0                         1.0  \n",
       "1                        0.0                         0.0  \n",
       "2                        0.0                         0.0  \n",
       "3                        NaN                         NaN  \n",
       "4                        0.0                         0.0  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aperçu de la structure des données principales\n",
    "import pandas as pd\n",
    "\n",
    "# Charger les premières lignes des fichiers clés pour comprendre leur structure\n",
    "print(\"Structure du fichier application_train.csv:\")\n",
    "app_train = pd.read_csv(os.path.join(DATA_PATH, 'application_train.csv'), nrows=5)\n",
    "print(f\"Shape: {app_train.shape}\")\n",
    "app_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b787552d",
   "metadata": {},
   "source": [
    "## Installation des dépendances spéciales pour macOS\n",
    "\n",
    "XGBoost nécessite la bibliothèque libomp sur macOS. Installons-la via Homebrew avant de continuer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5cd3bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Détection de macOS, installation de libomp pour XGBoost...\n",
      "/usr/local/bin/brew\n",
      "/usr/local/bin/brew\n",
      "Homebrew est installé, installation de libomp...\n",
      "Homebrew est installé, installation de libomp...\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://formulae.brew.sh/api/formula.jws.json\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://formulae.brew.sh/api/formula.jws.json\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://formulae.brew.sh/api/cask.jws.json\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://formulae.brew.sh/api/cask.jws.json\u001b[0m\n",
      "\u001b[33mWarning:\u001b[0m libomp 20.1.4 is already installed and up-to-date.\n",
      "To reinstall 20.1.4, run:\n",
      "  brew reinstall libomp\n",
      "\u001b[33mWarning:\u001b[0m libomp 20.1.4 is already installed and up-to-date.\n",
      "To reinstall 20.1.4, run:\n",
      "  brew reinstall libomp\n"
     ]
    }
   ],
   "source": [
    "# Vérifier si nous sommes sur macOS et installer libomp si nécessaire\n",
    "import platform\n",
    "import os\n",
    "\n",
    "if platform.system() == 'Darwin':  # macOS\n",
    "    print(\"Détection de macOS, installation de libomp pour XGBoost...\")\n",
    "    # Vérifier si Homebrew est installé\n",
    "    try:\n",
    "        !which brew\n",
    "        print(\"Homebrew est installé, installation de libomp...\")\n",
    "        !brew install libomp\n",
    "    except:\n",
    "        print(\"Homebrew n'est pas installé. Veuillez installer Homebrew puis libomp:\")\n",
    "        print(\"1. /bin/bash -c \\\"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\\\"\")\n",
    "        print(\"2. brew install libomp\")\n",
    "else:\n",
    "    print(f\"Système d'exploitation détecté: {platform.system()}. Pas besoin d'installation spéciale pour XGBoost.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ba9a2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installation de XGBoost avec les paramètres spécifiques pour macOS...\n",
      "Requirement already satisfied: xgboost in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.0.0)\n",
      "Requirement already satisfied: xgboost in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.0.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from xgboost) (1.14.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from xgboost) (1.14.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: lightgbm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.6.0)\n",
      "Requirement already satisfied: h5py in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.11.0)\n",
      "Requirement already satisfied: tensorflow in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.16.2)\n",
      "Requirement already satisfied: keras in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from lightgbm) (1.14.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.3.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (4.25.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.65.4)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: rich in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: optree in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras) (0.12.1)\n",
      "Requirement already satisfied: lightgbm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.6.0)\n",
      "Requirement already satisfied: h5py in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.11.0)\n",
      "Requirement already satisfied: tensorflow in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.16.2)\n",
      "Requirement already satisfied: keras in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from lightgbm) (1.14.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (0.3.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (4.25.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.65.4)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: rich in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: optree in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from keras) (0.12.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich->keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich->keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Installation des bibliothèques nécessaires avec options spécifiques pour macOS\n",
    "import platform\n",
    "\n",
    "if platform.system() == 'Darwin':  # macOS\n",
    "    print(\"Installation de XGBoost avec les paramètres spécifiques pour macOS...\")\n",
    "    !pip install --no-binary xgboost xgboost\n",
    "    !pip install lightgbm h5py tensorflow keras\n",
    "else:\n",
    "    !pip install xgboost lightgbm h5py tensorflow keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "801062fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avertissement: imbalanced-learn n'est pas disponible. SMOTE sera désactivé.\n"
     ]
    }
   ],
   "source": [
    "# Import des bibliothèques nécessaires\n",
    "import numpy as np  # pour les calculs mathématiques\n",
    "import pandas as pd  # pour la manipulation des données (csv)\n",
    "import matplotlib.pyplot as plt  # pour les graphiques\n",
    "import seaborn as sns  # pour plus d'options de graphiques (construit sur matplotlib)\n",
    "\n",
    "# Imports pour le machine learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer  # Remplace Imputer qui est obsolète\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Tenter d'importer XGBoost avec gestion d'erreurs\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    XGB_AVAILABLE = True\n",
    "except ImportError as e:\n",
    "    print(f\"Avertissement: XGBoost n'a pas pu être importé: {e}\")\n",
    "    print(\"Les fonctionnalités utilisant XGBoost seront désactivées.\")\n",
    "    XGB_AVAILABLE = False\n",
    "\n",
    "# Tenter d'importer LightGBM avec gestion d'erreurs\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    LGBM_AVAILABLE = True\n",
    "except ImportError as e:\n",
    "    print(f\"Avertissement: LightGBM n'a pas pu être importé: {e}\")\n",
    "    print(\"Les fonctionnalités utilisant LightGBM seront désactivées.\")\n",
    "    LGBM_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    IMBLEARN_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"Avertissement: imbalanced-learn n'est pas disponible. SMOTE sera désactivé.\")\n",
    "    IMBLEARN_AVAILABLE = False\n",
    "\n",
    "from scipy import stats\n",
    "import pickle\n",
    "import gc\n",
    "import os\n",
    "\n",
    "# Pour la sauvegarde de modèle au format h5\n",
    "import h5py\n",
    "import tempfile\n",
    "\n",
    "try:\n",
    "    from tensorflow import keras\n",
    "    import joblib\n",
    "    TF_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"Avertissement: TensorFlow/Keras n'est pas disponible. Le format h5 sera limité.\")\n",
    "    TF_AVAILABLE = False\n",
    "\n",
    "# Supprimer les avertissements inutiles pour que la présentation soit claire\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Afficher les graphiques dans le notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Configuration pour afficher plus de colonnes\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53684a1",
   "metadata": {},
   "source": [
    "## Chargement des données\n",
    "\n",
    "Dans cette section, nous allons charger les données Home Credit. Dans un environnement de production, nous chargerions les fichiers de données réels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "275a8172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement des données locales depuis le dossier data...\n",
      "Données d'entraînement chargées avec succès - 307511 lignes et 122 colonnes\n",
      "Erreur lors du chargement des données: name 'available_files' is not defined\n",
      "Utilisation des données simulées pour le moment...\n",
      "Données d'entraînement chargées avec succès - 307511 lignes et 122 colonnes\n",
      "Erreur lors du chargement des données: name 'available_files' is not defined\n",
      "Utilisation des données simulées pour le moment...\n"
     ]
    }
   ],
   "source": [
    "# Définition des chemins de fichiers\n",
    "DATA_PATH = \"../data/\"\n",
    "\n",
    "# Tenter de charger les données réelles depuis votre dossier local\n",
    "try:\n",
    "    print(\"Chargement des données locales depuis le dossier data...\")\n",
    "    train = pd.read_csv(os.path.join(DATA_PATH, 'application_train.csv'))\n",
    "    print(f\"Données d'entraînement chargées avec succès - {train.shape[0]} lignes et {train.shape[1]} colonnes\")\n",
    "    \n",
    "    if 'application_test.csv' in available_files:\n",
    "        test = pd.read_csv(os.path.join(DATA_PATH, 'application_test.csv'))\n",
    "        print(f\"Données de test chargées avec succès - {test.shape[0]} lignes et {test.shape[1]} colonnes\")\n",
    "    else:\n",
    "        # Créer un jeu de test à partir du jeu d'entraînement si le fichier test n'est pas disponible\n",
    "        print(\"Fichier application_test.csv non trouvé, création d'un échantillon de test à partir des données d'entraînement\")\n",
    "        # Séparer 20% des données d'entraînement pour le test\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        train_data, test_data = train_test_split(train, test_size=0.2, random_state=42)\n",
    "        train = train_data.reset_index(drop=True)\n",
    "        test = test_data.drop('TARGET', axis=1).reset_index(drop=True)\n",
    "        print(f\"Jeu de test créé avec {test.shape[0]} lignes\")\n",
    "    \n",
    "    # Créer un petit échantillon du jeu de test pour les prédictions rapides\n",
    "    new_test = test.iloc[:100].copy()\n",
    "    print(f\"Échantillon de test pour nouvelles prédictions: {new_test.shape}\")\n",
    "    \n",
    "    print(\"\\nDonnées chargées avec succès!\")\n",
    "    DATA_AVAILABLE = True\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors du chargement des données: {e}\")\n",
    "    print(\"Utilisation des données simulées pour le moment...\")\n",
    "    DATA_AVAILABLE = False\n",
    "    \n",
    "    # Code pour générer des données simulées (inchangé)\n",
    "    np.random.seed(42)\n",
    "    n_samples = 1000\n",
    "    \n",
    "    # Identifiants clients\n",
    "    client_ids = np.arange(n_samples)\n",
    "    \n",
    "    # Caractéristiques des prêts\n",
    "    loan_amounts = np.random.normal(15000, 5000, n_samples)\n",
    "    loan_terms = np.random.choice([12, 24, 36, 48, 60], n_samples)\n",
    "    interest_rates = np.random.uniform(0.03, 0.15, n_samples)\n",
    "    \n",
    "    # Caractéristiques des clients\n",
    "    ages = np.random.normal(40, 10, n_samples).astype(int)\n",
    "    incomes = np.random.normal(50000, 15000, n_samples)\n",
    "    employment_years = np.random.normal(7, 4, n_samples)\n",
    "    debt_to_income = np.random.normal(0.3, 0.1, n_samples)\n",
    "    credit_scores = np.random.normal(650, 100, n_samples).astype(int)\n",
    "    \n",
    "    # Historique de prêts\n",
    "    num_previous_loans = np.random.poisson(2, n_samples)\n",
    "    num_delinquencies = np.random.poisson(0.5, n_samples)\n",
    "    \n",
    "    # Création de la variable cible (défaut de paiement)\n",
    "    probabilities = 1.0 / (1.0 + np.exp(-(0.0001 * loan_amounts - 0.05 * employment_years \n",
    "                                      + 0.1 * debt_to_income - 0.0001 * credit_scores \n",
    "                                      + 0.2 * num_delinquencies - 3)))\n",
    "    target = np.random.binomial(1, probabilities)\n",
    "    \n",
    "    # Création du DataFrame\n",
    "    train = pd.DataFrame({\n",
    "        'SK_ID_CURR': client_ids,\n",
    "        'TARGET': target,\n",
    "        'NAME_CONTRACT_TYPE': np.random.choice(['Cash loans', 'Revolving loans'], n_samples),\n",
    "        'CODE_GENDER': np.random.choice(['M', 'F'], n_samples),\n",
    "        'FLAG_OWN_CAR': np.random.choice(['Y', 'N'], n_samples),\n",
    "        'FLAG_OWN_REALTY': np.random.choice(['Y', 'N'], n_samples),\n",
    "        'CNT_CHILDREN': np.random.poisson(0.5, n_samples),\n",
    "        'AMT_INCOME_TOTAL': incomes,\n",
    "        'AMT_CREDIT': loan_amounts,\n",
    "        'AMT_ANNUITY': loan_amounts * (interest_rates / 12) * (1 + interest_rates / 12) ** loan_terms / ((1 + interest_rates / 12) ** loan_terms - 1),\n",
    "        'AMT_GOODS_PRICE': loan_amounts * 0.9,\n",
    "        'DAYS_BIRTH': -ages * 365,  # Convertir l'âge en jours négatifs\n",
    "        'DAYS_EMPLOYED': -employment_years * 365,  # Convertir les années en jours négatifs\n",
    "        'REGION_POPULATION_RELATIVE': np.random.uniform(0.001, 0.07, n_samples),\n",
    "        'EXT_SOURCE_1': np.random.uniform(0, 1, n_samples),\n",
    "        'EXT_SOURCE_2': np.random.uniform(0, 1, n_samples),\n",
    "        'EXT_SOURCE_3': np.random.uniform(0, 1, n_samples),\n",
    "    })\n",
    "    \n",
    "    # Création d'un jeu de test qui ressemble au jeu d'entraînement mais sans la colonne TARGET\n",
    "    test = train.copy().drop('TARGET', axis=1).iloc[:int(n_samples/5)]\n",
    "    \n",
    "    # Création d'un jeu de test 'new_test' pour les prédictions\n",
    "    new_test = train.copy().drop('TARGET', axis=1).iloc[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02a1c98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour réduire l'utilisation de la mémoire\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" Réduit l'usage mémoire d'un DataFrame en convertissant les types de données \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Mémoire utilisée par le DataFrame: {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            \n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Mémoire utilisée après optimisation: {:.2f} MB'.format(end_mem))\n",
    "    print('Réduction de {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Optimiser l'utilisation de la mémoire si les données sont disponibles\n",
    "if DATA_AVAILABLE:\n",
    "    print(\"Optimisation de l'utilisation de la mémoire...\")\n",
    "    print(\"\\nOptimisation du jeu d'entraînement:\")\n",
    "    train = reduce_mem_usage(train)\n",
    "    print(\"\\nOptimisation du jeu de test:\")\n",
    "    test = reduce_mem_usage(test)\n",
    "    print(\"\\nOptimisation de l'échantillon de test:\")\n",
    "    new_test = reduce_mem_usage(new_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6237369",
   "metadata": {},
   "source": [
    "## Exploration des données\n",
    "\n",
    "Examinons les données pour comprendre leur structure et leurs caractéristiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df10a100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions du jeu d'entraînement: (1000, 17)\n",
      "Dimensions du jeu de test: (200, 16)\n",
      "Dimensions du nouveau jeu de test: (100, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>EXT_SOURCE_1</th>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "      <th>EXT_SOURCE_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>40394.034814</td>\n",
       "      <td>17483.570765</td>\n",
       "      <td>395.709049</td>\n",
       "      <td>15735.213689</td>\n",
       "      <td>-17155</td>\n",
       "      <td>-2262.127190</td>\n",
       "      <td>0.059961</td>\n",
       "      <td>0.460813</td>\n",
       "      <td>0.783607</td>\n",
       "      <td>0.688727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>37740.568087</td>\n",
       "      <td>14308.678494</td>\n",
       "      <td>1246.627856</td>\n",
       "      <td>12877.810645</td>\n",
       "      <td>-14600</td>\n",
       "      <td>-3336.165980</td>\n",
       "      <td>0.039912</td>\n",
       "      <td>0.478720</td>\n",
       "      <td>0.197452</td>\n",
       "      <td>0.951414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>38521.664510</td>\n",
       "      <td>18238.442691</td>\n",
       "      <td>549.471041</td>\n",
       "      <td>16414.598421</td>\n",
       "      <td>-17155</td>\n",
       "      <td>-4071.847672</td>\n",
       "      <td>0.045788</td>\n",
       "      <td>0.177668</td>\n",
       "      <td>0.558449</td>\n",
       "      <td>0.562367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>50094.267873</td>\n",
       "      <td>22615.149282</td>\n",
       "      <td>429.273935</td>\n",
       "      <td>20353.634354</td>\n",
       "      <td>-11315</td>\n",
       "      <td>-3329.533758</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>0.876208</td>\n",
       "      <td>0.113097</td>\n",
       "      <td>0.960756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>13487.354212</td>\n",
       "      <td>13829.233126</td>\n",
       "      <td>409.084647</td>\n",
       "      <td>12446.309814</td>\n",
       "      <td>-19710</td>\n",
       "      <td>-3775.298760</td>\n",
       "      <td>0.026665</td>\n",
       "      <td>0.525821</td>\n",
       "      <td>0.361435</td>\n",
       "      <td>0.892455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "0           0       1    Revolving loans           M            Y   \n",
       "1           1       0    Revolving loans           F            Y   \n",
       "2           2       0    Revolving loans           F            Y   \n",
       "3           3       0         Cash loans           F            Y   \n",
       "4           4       0    Revolving loans           F            N   \n",
       "\n",
       "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL    AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0               Y             1      40394.034814  17483.570765   395.709049   \n",
       "1               N             2      37740.568087  14308.678494  1246.627856   \n",
       "2               Y             0      38521.664510  18238.442691   549.471041   \n",
       "3               N             1      50094.267873  22615.149282   429.273935   \n",
       "4               Y             1      13487.354212  13829.233126   409.084647   \n",
       "\n",
       "   AMT_GOODS_PRICE  DAYS_BIRTH  DAYS_EMPLOYED  REGION_POPULATION_RELATIVE  \\\n",
       "0     15735.213689      -17155   -2262.127190                    0.059961   \n",
       "1     12877.810645      -14600   -3336.165980                    0.039912   \n",
       "2     16414.598421      -17155   -4071.847672                    0.045788   \n",
       "3     20353.634354      -11315   -3329.533758                    0.022200   \n",
       "4     12446.309814      -19710   -3775.298760                    0.026665   \n",
       "\n",
       "   EXT_SOURCE_1  EXT_SOURCE_2  EXT_SOURCE_3  \n",
       "0      0.460813      0.783607      0.688727  \n",
       "1      0.478720      0.197452      0.951414  \n",
       "2      0.177668      0.558449      0.562367  \n",
       "3      0.876208      0.113097      0.960756  \n",
       "4      0.525821      0.361435      0.892455  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examiner les dimensions des jeux de données\n",
    "print(\"Dimensions du jeu d'entraînement:\", train.shape)\n",
    "print(\"Dimensions du jeu de test:\", test.shape)\n",
    "print(\"Dimensions du nouveau jeu de test:\", new_test.shape)\n",
    "\n",
    "# Afficher les premières lignes du jeu d'entraînement\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e721ac02",
   "metadata": {},
   "source": [
    "## 1. Chargement des données\n",
    "\n",
    "Dans cette section, nous allons charger les données de Home Credit. Les données sont dispersées dans plusieurs tables qu'il faudra joindre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e93d21aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes avec valeurs manquantes dans le jeu d'entraînement:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Count</th>\n",
       "      <th>Missing Count Ratio</th>\n",
       "      <th>Missing Count %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Missing Count, Missing Count Ratio, Missing Count %]\n",
       "Index: []"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fonction pour trouver les colonnes avec des valeurs manquantes\n",
    "def missing_columns(dataframe):\n",
    "    \"\"\"\n",
    "    Renvoie un dataframe contenant les noms des colonnes manquantes et \n",
    "    le pourcentage de valeurs manquantes par rapport à l'ensemble du dataframe.\n",
    "    \n",
    "    dataframe: dataframe qui donne les noms des colonnes et leur % de valeurs manquantes\n",
    "    \"\"\"\n",
    "    \n",
    "    # Trouver les valeurs manquantes\n",
    "    missing_values = dataframe.isnull().sum().sort_values(ascending=False)\n",
    "    \n",
    "    # Pourcentage de valeurs manquantes par rapport à la taille totale\n",
    "    missing_values_pct = 100 * missing_values/len(dataframe)\n",
    "    \n",
    "    # Créer un nouveau dataframe qui est une version concaténée\n",
    "    concat_values = pd.concat([missing_values, missing_values/len(dataframe), missing_values_pct.round(1)], axis=1)\n",
    "\n",
    "    # Donner de nouveaux noms de colonne\n",
    "    concat_values.columns = ['Missing Count', 'Missing Count Ratio', 'Missing Count %']\n",
    "    \n",
    "    # Retourner les valeurs requises\n",
    "    return concat_values[concat_values.iloc[:,1]!=0]\n",
    "    \n",
    "# Afficher les colonnes avec des valeurs manquantes\n",
    "print(\"Colonnes avec valeurs manquantes dans le jeu d'entraînement:\")\n",
    "missing_columns(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c98b761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes avec valeurs manquantes dans le jeu d'entraînement:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Count</th>\n",
       "      <th>Missing Count Ratio</th>\n",
       "      <th>Missing Count %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Missing Count, Missing Count Ratio, Missing Count %]\n",
       "Index: []"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fonction pour trouver les colonnes avec des valeurs manquantes\n",
    "def missing_columns(dataframe):\n",
    "    \"\"\"\n",
    "    Renvoie un dataframe contenant les noms des colonnes manquantes et \n",
    "    le pourcentage de valeurs manquantes par rapport à l'ensemble du dataframe.\n",
    "    \n",
    "    dataframe: dataframe qui donne les noms des colonnes et leur % de valeurs manquantes\n",
    "    \"\"\"\n",
    "    \n",
    "    # Trouver les valeurs manquantes\n",
    "    missing_values = dataframe.isnull().sum().sort_values(ascending=False)\n",
    "    \n",
    "    # Pourcentage de valeurs manquantes par rapport à la taille totale\n",
    "    missing_values_pct = 100 * missing_values/len(dataframe)\n",
    "    \n",
    "    # Créer un nouveau dataframe qui est une version concaténée\n",
    "    concat_values = pd.concat([missing_values, missing_values/len(dataframe), missing_values_pct.round(1)], axis=1)\n",
    "\n",
    "    # Donner de nouveaux noms de colonne\n",
    "    concat_values.columns = ['Missing Count', 'Missing Count Ratio', 'Missing Count %']\n",
    "    \n",
    "    # Retourner les valeurs requises\n",
    "    return concat_values[concat_values.iloc[:,1]!=0]\n",
    "    \n",
    "# Afficher les colonnes avec des valeurs manquantes\n",
    "print(\"Colonnes avec valeurs manquantes dans le jeu d'entraînement:\")\n",
    "missing_columns(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37e98d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    1000.000000\n",
       "mean       39.553000\n",
       "std        10.095995\n",
       "min         7.000000\n",
       "25%        33.000000\n",
       "50%        40.000000\n",
       "75%        46.000000\n",
       "max        72.000000\n",
       "Name: DAYS_BIRTH, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explorer l'âge des clients\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.distplot(train['DAYS_BIRTH'] / -365, bins=25, kde=False)\n",
    "plt.xlabel(\"Âge du client (années)\")\n",
    "plt.title('Distribution des âges')\n",
    "plt.show()\n",
    "\n",
    "# Statistiques de l'âge\n",
    "(train['DAYS_BIRTH'] / -365).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0876f50",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n",
    "\n",
    "Créons de nouvelles caractéristiques qui pourraient être utiles pour la prédiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ab703be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'anomalies avec 1000 ans d'emploi: 0\n",
      "Pas assez d'anomalies pour calculer le taux de défaut\n",
      "Non-anomalies ont un taux de défaut de 15.90%\n"
     ]
    }
   ],
   "source": [
    "# Vérifier les anomalies dans DAYS_EMPLOYED\n",
    "thousand_anomalies = train[(train['DAYS_EMPLOYED']/365 >= 900) & (train['DAYS_EMPLOYED']/365 <= 1100)]\n",
    "print(f\"Nombre d'anomalies avec 1000 ans d'emploi: {len(thousand_anomalies)}\")\n",
    "\n",
    "# Comparer le taux de défaut entre les anomalies et les non-anomalies\n",
    "anomalies_index = pd.Index(thousand_anomalies.index)\n",
    "non_anomalies_index = train.index.difference(anomalies_index)\n",
    "non_anomalies = train.iloc[non_anomalies_index]\n",
    "\n",
    "anomalies_target = thousand_anomalies['TARGET'].value_counts()\n",
    "non_anomalies_target = non_anomalies['TARGET'].value_counts()\n",
    "\n",
    "if len(anomalies_target) > 1 and 1 in anomalies_target and 0 in anomalies_target:\n",
    "    print(f\"Anomalies ont un taux de défaut de {100*anomalies_target[1]/(anomalies_target[1]+anomalies_target[0]):.2f}%\")\n",
    "else:\n",
    "    print(\"Pas assez d'anomalies pour calculer le taux de défaut\")\n",
    "    \n",
    "if len(non_anomalies_target) > 1 and 1 in non_anomalies_target and 0 in non_anomalies_target:\n",
    "    print(f\"Non-anomalies ont un taux de défaut de {100*non_anomalies_target[1]/(non_anomalies_target[1]+non_anomalies_target[0]):.2f}%\")\n",
    "else:\n",
    "    print(\"Pas assez de non-anomalies pour calculer le taux de défaut\")\n",
    "\n",
    "# Créer une colonne indicatrice d'anomalie et remplacer les valeurs anomaliques par NaN\n",
    "train['DAYS_EMPLOYED_ANOM'] = train[\"DAYS_EMPLOYED\"] == 365243\n",
    "train['DAYS_EMPLOYED'] = train['DAYS_EMPLOYED'].replace({365243: np.nan})\n",
    "\n",
    "# Faire de même pour les jeux de test\n",
    "test['DAYS_EMPLOYED_ANOM'] = test[\"DAYS_EMPLOYED\"] == 365243\n",
    "test['DAYS_EMPLOYED'] = test['DAYS_EMPLOYED'].replace({365243: np.nan})\n",
    "\n",
    "new_test['DAYS_EMPLOYED_ANOM'] = new_test[\"DAYS_EMPLOYED\"] == 365243\n",
    "new_test['DAYS_EMPLOYED'] = new_test['DAYS_EMPLOYED'].replace({365243: np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7965fb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables les plus négativement corrélées à TARGET:\n",
      "AMT_INCOME_TOTAL             -0.023258\n",
      "EXT_SOURCE_1                 -0.015014\n",
      "REGION_POPULATION_RELATIVE   -0.012862\n",
      "EXT_SOURCE_3                 -0.004141\n",
      "DAYS_BIRTH                    0.007297\n",
      "EXT_SOURCE_2                  0.015739\n",
      "CNT_CHILDREN                  0.028160\n",
      "SK_ID_CURR                    0.051283\n",
      "AMT_ANNUITY                   0.085152\n",
      "DAYS_EMPLOYED                 0.088019\n",
      "Name: TARGET, dtype: float64\n",
      "\n",
      "Variables les plus positivement corrélées à TARGET:\n",
      "DAYS_BIRTH            0.007297\n",
      "EXT_SOURCE_2          0.015739\n",
      "CNT_CHILDREN          0.028160\n",
      "SK_ID_CURR            0.051283\n",
      "AMT_ANNUITY           0.085152\n",
      "DAYS_EMPLOYED         0.088019\n",
      "AMT_CREDIT            0.150562\n",
      "AMT_GOODS_PRICE       0.150562\n",
      "TARGET                1.000000\n",
      "DAYS_EMPLOYED_ANOM         NaN\n",
      "Name: TARGET, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Explorer les corrélations avec la variable cible\n",
    "# Utiliser numeric_only=True pour éviter l'erreur avec les colonnes non numériques\n",
    "corr_train = train.corr(numeric_only=True)['TARGET'].sort_values()\n",
    "\n",
    "# Afficher les 10 variables les plus négativement corrélées\n",
    "print(\"Variables les plus négativement corrélées à TARGET:\")\n",
    "print(corr_train.head(10))\n",
    "\n",
    "# Afficher les 10 variables les plus positivement corrélées\n",
    "print(\"\\nVariables les plus positivement corrélées à TARGET:\")\n",
    "print(corr_train.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5a7594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de corrélation pour les variables numériques\n",
    "plt.figure(figsize=(16, 14))\n",
    "# Sélectionner uniquement les colonnes numériques\n",
    "numeric_vars = train.select_dtypes(include=[np.number]).columns\n",
    "# Limiter à 20 variables pour une meilleure lisibilité\n",
    "selected_vars = list(numeric_vars[:20])\n",
    "if 'TARGET' in train.columns and 'TARGET' not in selected_vars:\n",
    "    selected_vars.append('TARGET')\n",
    "sns.heatmap(train[selected_vars].corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Matrice de corrélation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e495a2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explorer les corrélations avec la variable cible\n",
    "# Utiliser numeric_only=True pour éviter l'erreur avec les colonnes non numériques\n",
    "corr_train = train.corr(numeric_only=True)['TARGET'].sort_values()\n",
    "\n",
    "# Afficher les 10 variables les plus négativement corrélées\n",
    "print(\"Variables les plus négativement corrélées à TARGET:\")\n",
    "print(corr_train.head(10))\n",
    "\n",
    "# Afficher les 10 variables les plus positivement corrélées\n",
    "print(\"\\nVariables les plus positivement corrélées à TARGET:\")\n",
    "print(corr_train.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962711e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation des valeurs manquantes et mise à l'échelle des données\n",
    "\n",
    "# Séparer les variables et la cible\n",
    "features = [col for col in train.columns if col != 'TARGET']\n",
    "target = train['TARGET'].values\n",
    "\n",
    "# Remplacer les valeurs infinies par 0\n",
    "train = train.replace([np.inf, -np.inf], np.nan)\n",
    "test = test.replace([np.inf, -np.inf], np.nan)\n",
    "new_test = new_test.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Créer un SimpleImputer pour remplacer les valeurs manquantes par la médiane\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "imputer.fit(train[features])\n",
    "\n",
    "# Transformer les jeux de données\n",
    "train_transformed = imputer.transform(train[features])\n",
    "test_transformed = imputer.transform(test[features])\n",
    "new_test_transformed = imputer.transform(new_test)\n",
    "\n",
    "# Mise à l'échelle des données\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "train_transformed = scaler.fit_transform(train_transformed)\n",
    "test_transformed = scaler.transform(test_transformed)\n",
    "new_test_transformed = scaler.transform(new_test_transformed)\n",
    "\n",
    "print(f\"Dimensions après transformation:\")\n",
    "print(f\"Train transformé: {train_transformed.shape}\")\n",
    "print(f\"Test transformé: {test_transformed.shape}\")\n",
    "print(f\"New test transformé: {new_test_transformed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01db676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création de variables basées sur l'expertise du domaine\n",
    "# Ces variables sont mentionnées dans l'article de Wells Fargo sur les facteurs de crédit\n",
    "\n",
    "# debt-to-income ratio (DIR) = Montant du crédit / Revenu total\n",
    "train['DIR'] = train['AMT_CREDIT'] / train['AMT_INCOME_TOTAL']\n",
    "test['DIR'] = test['AMT_CREDIT'] / test['AMT_INCOME_TOTAL']\n",
    "new_test['DIR'] = new_test['AMT_CREDIT'] / new_test['AMT_INCOME_TOTAL']\n",
    "\n",
    "# annuity-to-income ratio (AIR) = Annuité du prêt / Revenu total\n",
    "train['AIR'] = train['AMT_ANNUITY'] / train['AMT_INCOME_TOTAL']\n",
    "test['AIR'] = test['AMT_ANNUITY'] / test['AMT_INCOME_TOTAL']\n",
    "new_test['AIR'] = new_test['AMT_ANNUITY'] / new_test['AMT_INCOME_TOTAL']\n",
    "\n",
    "# annuity-to-credit ratio (ACR) = Annuité du prêt / Montant du crédit\n",
    "train['ACR'] = train['AMT_ANNUITY'] / train['AMT_CREDIT']\n",
    "test['ACR'] = test['AMT_ANNUITY'] / test['AMT_CREDIT']\n",
    "new_test['ACR'] = new_test['AMT_ANNUITY'] / new_test['AMT_CREDIT']\n",
    "\n",
    "# days-employed-to-age ratio (DAR) = Jours employés / Âge du demandeur\n",
    "train['DAR'] = train['DAYS_EMPLOYED'] / train['DAYS_BIRTH']\n",
    "test['DAR'] = test['DAYS_EMPLOYED'] / test['DAYS_BIRTH']\n",
    "new_test['DAR'] = new_test['DAYS_EMPLOYED'] / new_test['DAYS_BIRTH']\n",
    "\n",
    "# Vérifier les corrélations des nouvelles variables avec TARGET\n",
    "domain_features = ['DIR', 'AIR', 'ACR', 'DAR']\n",
    "domain_corrs = train[domain_features + ['TARGET']].corr(numeric_only=True)['TARGET']\n",
    "print(\"Corrélations des variables d'expertise de domaine avec TARGET:\")\n",
    "print(domain_corrs[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424ee09c",
   "metadata": {},
   "source": [
    "## Préparation des données pour la modélisation\n",
    "\n",
    "Avant de construire des modèles, nous devons préparer les données en encodant les variables catégorielles et en traitant les valeurs manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d6f29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder les variables catégorielles avec 2 catégories ou moins\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "transform_counter = 0\n",
    "\n",
    "# Vérifier si le jeu de données contient des variables de type 'object'\n",
    "if 'object' in train.dtypes.values:\n",
    "    # Itérer à travers toutes les colonnes catégorielles\n",
    "    for col in train.select_dtypes('object').columns:\n",
    "        # Sélectionner uniquement les colonnes où le nombre de valeurs uniques est inférieur ou égal à 2\n",
    "        if train[col].nunique() <= 2:\n",
    "            train[col] = le.fit_transform(train[col].astype(str))\n",
    "            # Vérifier si la colonne existe dans les jeux de test\n",
    "            if col in test.columns:\n",
    "                test[col] = le.transform(test[col].astype(str))\n",
    "            if col in new_test.columns:\n",
    "                new_test[col] = le.transform(new_test[col].astype(str))\n",
    "            transform_counter += 1\n",
    "    \n",
    "    print(f\"Encodage par étiquettes appliqué à {transform_counter} colonnes.\")\n",
    "    \n",
    "    # One-hot encoding pour les variables catégorielles restantes\n",
    "    train = pd.get_dummies(train, drop_first=True)\n",
    "    test = pd.get_dummies(test, drop_first=True)\n",
    "    new_test = pd.get_dummies(new_test, drop_first=True)\n",
    "    \n",
    "    # Aligner les colonnes entre train et test\n",
    "    target = train['TARGET']\n",
    "    train, test = train.align(test, join='inner', axis=1)\n",
    "    train['TARGET'] = target\n",
    "    \n",
    "    # S'assurer que new_test a les mêmes colonnes que train\n",
    "    for col in train.columns:\n",
    "        if col != 'TARGET' and col not in new_test.columns:\n",
    "            new_test[col] = 0\n",
    "    new_test = new_test[train.columns[train.columns != 'TARGET']]\n",
    "    \n",
    "    print(f\"Dimensions après encodage one-hot:\")\n",
    "    print(f\"Train: {train.shape}\")\n",
    "    print(f\"Test: {test.shape}\")\n",
    "    print(f\"New test: {new_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7017969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de corrélation pour les variables numériques\n",
    "plt.figure(figsize=(16, 14))\n",
    "numeric_vars = train.select_dtypes(include=[np.number]).columns\n",
    "# Limiter à 20 variables pour une meilleure lisibilité\n",
    "selected_vars = list(numeric_vars[:20])\n",
    "if 'TARGET' in train.columns and 'TARGET' not in selected_vars:\n",
    "    selected_vars.append('TARGET')\n",
    "sns.heatmap(train[selected_vars].corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Matrice de corrélation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc465ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparer les prédictions de probabilité pour la soumission\n",
    "log_regression_pred_test = logistic_regressor.predict_proba(test_transformed)[:, 1]\n",
    "\n",
    "# Créer un DataFrame pour la soumission\n",
    "submission_log_regression = pd.DataFrame({'SK_ID_CURR': test['SK_ID_CURR'], 'TARGET': log_regression_pred_test})\n",
    "submission_log_regression.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c833d3",
   "metadata": {},
   "source": [
    "## Modélisation\n",
    "\n",
    "Nous allons entraîner plusieurs modèles de classification et évaluer leurs performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle XGBoost (conditionnel)\n",
    "if 'XGB_AVAILABLE' in globals() and XGB_AVAILABLE:\n",
    "    xgb_classifier = XGBClassifier(n_estimators=250, max_depth=5)\n",
    "    xgb_classifier.fit(X_training_set, y_training_set)\n",
    "    \n",
    "    # Prédictions sur l'ensemble de validation\n",
    "    xgb_pred = xgb_classifier.predict(X_validation_set)\n",
    "    xgb_pred_proba = xgb_classifier.predict_proba(X_validation_set)[:, 1]\n",
    "    \n",
    "    # Évaluation du modèle\n",
    "    print(\"XGBoost - Rapport de classification:\")\n",
    "    print(classification_report(y_validation_set, xgb_pred))\n",
    "    print(f\"AUC-ROC: {roc_auc_score(y_validation_set, xgb_pred_proba):.4f}\")\n",
    "    \n",
    "    # Prédictions sur le nouveau jeu de test\n",
    "    xgb_new = xgb_classifier.predict(new_test_transformed)\n",
    "    print(\"\\nDistribution des prédictions sur le nouveau jeu de test:\")\n",
    "    print(pd.Series(xgb_new).value_counts())\n",
    "else:\n",
    "    print(\"XGBoost n'est pas disponible. Passage à l'étape suivante.\")\n",
    "    # Définir des valeurs vides pour ne pas casser le code plus tard\n",
    "    xgb_classifier = None\n",
    "    xgb_pred = np.zeros(len(y_validation_set))\n",
    "    xgb_pred_proba = np.zeros(len(y_validation_set))\n",
    "    xgb_new = np.zeros(len(new_test_transformed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser l'importance des caractéristiques du modèle XGBoost\n",
    "xgb_importance = plot_importance(xgb_classifier, features, top_n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0563ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparer les prédictions de probabilité pour la soumission\n",
    "log_regression_pred_test = logistic_regressor.predict_proba(test_transformed)[:, 1]\n",
    "\n",
    "# Créer un DataFrame pour la soumission\n",
    "submission_log_regression = pd.DataFrame({'SK_ID_CURR': test['SK_ID_CURR'], 'TARGET': log_regression_pred_test})\n",
    "submission_log_regression.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a49a22b",
   "metadata": {},
   "source": [
    "### 2. Random Forest (Forêt aléatoire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e56692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle Random Forest\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=50, verbose=1, n_jobs=-1)\n",
    "random_forest.fit(X_training_set, y_training_set)\n",
    "\n",
    "# Prédictions sur l'ensemble de validation\n",
    "random_forest_pred = random_forest.predict(X_validation_set)\n",
    "random_forest_pred_proba = random_forest.predict_proba(X_validation_set)[:, 1]\n",
    "\n",
    "# Évaluation du modèle\n",
    "print(\"Random Forest - Rapport de classification:\")\n",
    "print(classification_report(y_validation_set, random_forest_pred))\n",
    "print(f\"AUC-ROC: {roc_auc_score(y_validation_set, random_forest_pred_proba):.4f}\")\n",
    "\n",
    "# Prédictions sur le nouveau jeu de test\n",
    "random_forest_new = random_forest.predict(new_test_transformed)\n",
    "print(\"\\nDistribution des prédictions sur le nouveau jeu de test:\")\n",
    "print(pd.Series(random_forest_new).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cbd59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyser l'importance des caractéristiques\n",
    "def plot_importance(model, features, top_n=20):\n",
    "    \"\"\"Affiche un graphique des caractéristiques les plus importantes.\"\"\"\n",
    "    # Créer un DataFrame pour l'importance des caractéristiques\n",
    "    feature_importance_df = pd.DataFrame({'Feature': features, 'Importance': model.feature_importances_})\n",
    "    feature_importance_df = feature_importance_df.sort_values('Importance', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    # Créer le graphique\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=feature_importance_df.head(top_n))\n",
    "    plt.title(f\"Les {top_n} caractéristiques les plus importantes\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return feature_importance_df\n",
    "\n",
    "# Visualiser l'importance des caractéristiques du modèle Random Forest\n",
    "rf_importance = plot_importance(random_forest, features, top_n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f45538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier l'importance des caractéristiques créées par expertise de domaine\n",
    "domain_features = ['DIR', 'AIR', 'ACR', 'DAR']\n",
    "domain_indices = [i for i, feature in enumerate(features) if feature in domain_features]\n",
    "\n",
    "if domain_indices:\n",
    "    domain_importance = pd.DataFrame({\n",
    "        'Feature': [features[i] for i in domain_indices],\n",
    "        'Importance': [random_forest.feature_importances_[i] for i in domain_indices]\n",
    "    })\n",
    "    domain_importance = domain_importance.sort_values('Importance', ascending=False)\n",
    "    print(\"Importance des caractéristiques créées par expertise de domaine:\")\n",
    "    print(domain_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baffdd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparer les prédictions pour la soumission\n",
    "random_forest_pred_test = random_forest.predict_proba(test_transformed)[:, 1]\n",
    "submission_rf = pd.DataFrame({'SK_ID_CURR': test['SK_ID_CURR'], 'TARGET': random_forest_pred_test})\n",
    "submission_rf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c69dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparer les prédictions pour la soumission\n",
    "xgb_pred_test = xgb_classifier.predict_proba(test_transformed)[:, 1]\n",
    "submission_xgb = pd.DataFrame({'SK_ID_CURR': test['SK_ID_CURR'], 'TARGET': xgb_pred_test})\n",
    "submission_xgb.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a723f4b",
   "metadata": {},
   "source": [
    "### 4. LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31246bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration de base pour LightGBM (conditionnel)\n",
    "if 'LGBM_AVAILABLE' in globals() and LGBM_AVAILABLE:\n",
    "    def get_lgbm_params():\n",
    "        params = {\n",
    "            'objective': 'binary',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'n_estimators': 100,\n",
    "            'learning_rate': 0.1,\n",
    "            'num_leaves': 40,\n",
    "            'max_depth': -1,  # -1 signifie pas de limite\n",
    "            'subsample': 1.0,\n",
    "            'colsample_bytree': 1.0,\n",
    "            'reg_alpha': 0.0,\n",
    "            'reg_lambda': 0.0,\n",
    "            'n_jobs': -1,\n",
    "            'random_state': 50\n",
    "        }\n",
    "        return params\n",
    "    \n",
    "    # Fonction d'évaluation avec arrêt précoce\n",
    "    def train_lgbm_model(X_train, y_train, X_val, y_val, params):\n",
    "        model = lgb.LGBMClassifier(**params)\n",
    "        \n",
    "        # Configuration de l'arrêt précoce\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            eval_metric='auc',\n",
    "            early_stopping_rounds=50,\n",
    "            verbose=10\n",
    "        )\n",
    "        \n",
    "        # Évaluation sur l'ensemble de validation\n",
    "        val_pred = model.predict_proba(X_val)[:, 1]\n",
    "        val_auc = roc_auc_score(y_val, val_pred)\n",
    "        print(f\"Validation AUC: {val_auc:.4f}\")\n",
    "        \n",
    "        return model, val_auc\n",
    "    \n",
    "    # Diviser les données d'entraînement pour la validation\n",
    "    X_train_lgb, X_val, y_train_lgb, y_val = train_test_split(X_training_set, y_training_set, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Entraîner le modèle LightGBM\n",
    "    lgb_params = get_lgbm_params()\n",
    "    lgb_model, val_auc = train_lgbm_model(X_train_lgb, y_train_lgb, X_val, y_val, lgb_params)\n",
    "else:\n",
    "    print(\"LightGBM n'est pas disponible. Passage à l'étape suivante.\")\n",
    "    # Définir des valeurs vides\n",
    "    lgb_model = None\n",
    "    lgb_pred = np.zeros(len(y_validation_set))\n",
    "    lgb_pred_proba = np.zeros(len(y_validation_set))\n",
    "    lgb_new = np.zeros(len(new_test_transformed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922801e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluer le modèle LightGBM sur l'ensemble de validation\n",
    "lgb_pred = lgb_model.predict(X_validation_set)\n",
    "lgb_pred_proba = lgb_model.predict_proba(X_validation_set)[:, 1]\n",
    "\n",
    "print(\"LightGBM - Rapport de classification:\")\n",
    "print(classification_report(y_validation_set, lgb_pred))\n",
    "print(f\"AUC-ROC: {roc_auc_score(y_validation_set, lgb_pred_proba):.4f}\")\n",
    "\n",
    "# Prédictions sur le nouveau jeu de test\n",
    "lgb_new = lgb_model.predict(new_test_transformed)\n",
    "print(\"\\nDistribution des prédictions sur le nouveau jeu de test:\")\n",
    "print(pd.Series(lgb_new).value_counts())\n",
    "\n",
    "# Visualiser l'importance des caractéristiques\n",
    "lgb_importance_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': lgb_model.feature_importances_ / sum(lgb_model.feature_importances_)\n",
    "})\n",
    "lgb_importance = plot_importance(lgb_model, features, top_n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bba0e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparer les prédictions pour la soumission\n",
    "lgb_pred_test = lgb_model.predict_proba(test_transformed)[:, 1]\n",
    "submission_lgb = pd.DataFrame({'SK_ID_CURR': test['SK_ID_CURR'], 'TARGET': lgb_pred_test})\n",
    "submission_lgb.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9585558b",
   "metadata": {},
   "source": [
    "### 5. Modèle d'ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f111db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un modèle d'ensemble par vote majoritaire\n",
    "def stacked_model(predictions):\n",
    "    \"\"\"Effectue un vote majoritaire sur les prédictions de plusieurs modèles.\"\"\"\n",
    "    stacked_predictions = np.array([])\n",
    "    \n",
    "    for element in predictions:\n",
    "        stacked_predictions = np.append(stacked_predictions, stats.mode(element)[0][0])\n",
    "        \n",
    "    return stacked_predictions\n",
    "\n",
    "# Combiner toutes les prédictions en un tableau multidimensionnel\n",
    "combined_array = np.column_stack([\n",
    "    log_regression_pred,\n",
    "    xgb_pred,\n",
    "    lgb_pred,\n",
    "    random_forest_pred\n",
    "])\n",
    "\n",
    "# Faire des prédictions avec le modèle par ensemble\n",
    "stacked_model_pred = stacked_model(combined_array)\n",
    "\n",
    "# Évaluer le modèle d'ensemble\n",
    "print(\"Modèle d'ensemble - Rapport de classification:\")\n",
    "print(classification_report(y_validation_set, stacked_model_pred))\n",
    "print(f\"AUC-ROC: {roc_auc_score(y_validation_set, stacked_model_pred):.4f}\")\n",
    "\n",
    "# Prédictions sur le nouveau jeu de test\n",
    "combined_new = np.column_stack([\n",
    "    logistic_new,\n",
    "    xgb_new,\n",
    "    lgb_new,\n",
    "    random_forest_new\n",
    "])\n",
    "stacked_new = stacked_model(combined_new).astype(int)\n",
    "print(\"\\nDistribution des prédictions d'ensemble sur le nouveau jeu de test:\")\n",
    "print(pd.Series(stacked_new).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26fa519",
   "metadata": {},
   "source": [
    "## Sélection et sauvegarde du meilleur modèle\n",
    "\n",
    "Nous allons sauvegarder notre meilleur modèle au format .h5 pour l'utiliser ultérieurement dans l'application web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57df10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluer tous les modèles disponibles sur l'ensemble de validation\n",
    "models = {\n",
    "    'Logistic Regression': {'model': logistic_regressor, 'auc': roc_auc_score(y_validation_set, log_regression_pred_proba)}\n",
    "}\n",
    "\n",
    "# Ajouter Random Forest si disponible\n",
    "if 'random_forest' in globals() and random_forest is not None:\n",
    "    models['Random Forest'] = {\n",
    "        'model': random_forest, \n",
    "        'auc': roc_auc_score(y_validation_set, random_forest_pred_proba)\n",
    "    }\n",
    "\n",
    "# Ajouter XGBoost si disponible\n",
    "if 'XGB_AVAILABLE' in globals() and XGB_AVAILABLE and xgb_classifier is not None:\n",
    "    models['XGBoost'] = {\n",
    "        'model': xgb_classifier, \n",
    "        'auc': roc_auc_score(y_validation_set, xgb_pred_proba)\n",
    "    }\n",
    "\n",
    "# Ajouter LightGBM si disponible\n",
    "if 'LGBM_AVAILABLE' in globals() and LGBM_AVAILABLE and lgb_model is not None:\n",
    "    models['LightGBM'] = {\n",
    "        'model': lgb_model, \n",
    "        'auc': roc_auc_score(y_validation_set, lgb_pred_proba)\n",
    "    }\n",
    "\n",
    "# Trouver le meilleur modèle\n",
    "best_model_name = max(models, key=lambda x: models[x]['auc'])\n",
    "best_model = models[best_model_name]['model']\n",
    "best_auc = models[best_model_name]['auc']\n",
    "\n",
    "print(f\"Le meilleur modèle est {best_model_name} avec un AUC-ROC de {best_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c10cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer le répertoire models s'il n'existe pas\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Fonction pour sauvegarder différents types de modèles au format h5\n",
    "def save_model_as_h5(model, model_name):\n",
    "    \"\"\"\n",
    "    Sauvegarde un modèle au format h5 selon son type\n",
    "    \"\"\"\n",
    "    file_path = f'../models/{model_name}.h5'\n",
    "    \n",
    "    if 'LGBM_AVAILABLE' in globals() and LGBM_AVAILABLE and isinstance(model, lgb.LGBMModel):  # LightGBM models\n",
    "        model.booster_.save_model(file_path)\n",
    "        print(f\"Modèle LightGBM sauvegardé dans {file_path}\")\n",
    "        \n",
    "    elif 'XGB_AVAILABLE' in globals() and XGB_AVAILABLE and isinstance(model, XGBClassifier):  # XGBoost models\n",
    "        model.save_model(file_path)\n",
    "        print(f\"Modèle XGBoost sauvegardé dans {file_path}\")\n",
    "        \n",
    "    else:  # Scikit-learn models (RandomForest, LogisticRegression, etc.)\n",
    "        # Essayer de sauvegarder au format h5 si TensorFlow est disponible\n",
    "        if 'TF_AVAILABLE' in globals() and TF_AVAILABLE:\n",
    "            from tensorflow.keras.models import Sequential\n",
    "            from tensorflow.keras.layers import Dense\n",
    "            \n",
    "            # Sauvegarder d'abord le modèle sklearn en utilisant pickle temporairement\n",
    "            temp_file = tempfile.NamedTemporaryFile(delete=False).name\n",
    "            with open(temp_file, 'wb') as f:\n",
    "                pickle.dump(model, f)\n",
    "                \n",
    "            # Créer un modèle keras qui servira de conteneur\n",
    "            container_model = Sequential()\n",
    "            container_model.add(Dense(1, input_shape=(1,)))\n",
    "            \n",
    "            # Sauvegarder au format h5\n",
    "            container_model.save(file_path)\n",
    "            \n",
    "            # Ajouter le modèle sklearn comme attribut personnalisé\n",
    "            with h5py.File(file_path, 'a') as h5file:\n",
    "                sklearn_group = h5file.create_group('sklearn_model')\n",
    "                with open(temp_file, 'rb') as f:\n",
    "                    sklearn_group.create_dataset('model_dump', data=np.void(f.read()))\n",
    "                    \n",
    "            # Supprimer le fichier temporaire\n",
    "            os.remove(temp_file)\n",
    "            print(f\"Modèle {model.__class__.__name__} sauvegardé dans {file_path}\")\n",
    "        else:\n",
    "            # Utiliser pickle si TensorFlow n'est pas disponible\n",
    "            with open(file_path.replace('.h5', '.pkl'), 'wb') as f:\n",
    "                pickle.dump(model, f)\n",
    "            print(f\"TensorFlow n'est pas disponible. Modèle sauvegardé au format pickle: {file_path.replace('.h5', '.pkl')}\")\n",
    "    \n",
    "    # Sauvegarder également les métadonnées du modèle\n",
    "    metadata = {\n",
    "        'model_type': model.__class__.__name__,\n",
    "        'auc_score': models[best_model_name]['auc'],\n",
    "        'features': features\n",
    "    }\n",
    "    \n",
    "    with h5py.File(f'../models/{model_name}_metadata.h5', 'w') as h5file:\n",
    "        h5file.attrs['model_type'] = metadata['model_type']\n",
    "        h5file.attrs['auc_score'] = metadata['auc_score']\n",
    "        feature_group = h5file.create_group('features')\n",
    "        for i, feature in enumerate(features):\n",
    "            feature_group.attrs[f'feature_{i}'] = feature\n",
    "            \n",
    "    return file_path\n",
    "\n",
    "# Sauvegarder le meilleur modèle au format h5 ou pickle\n",
    "model_path = save_model_as_h5(best_model, best_model_name.lower().replace(' ', '_'))\n",
    "\n",
    "# Sauvegarder également l'imputer et le scaler pour une utilisation future\n",
    "with h5py.File('../models/preprocessing.h5', 'w') as h5file:\n",
    "    # Sauvegarder l'imputer et le scaler en tant qu'attributs personnalisés\n",
    "    imputer_temp = tempfile.NamedTemporaryFile(delete=False).name\n",
    "    scaler_temp = tempfile.NamedTemporaryFile(delete=False).name\n",
    "    \n",
    "    with open(imputer_temp, 'wb') as f:\n",
    "        pickle.dump(imputer, f)\n",
    "    with open(scaler_temp, 'wb') as f:\n",
    "        pickle.dump(scaler, f)\n",
    "        \n",
    "    # Créer des groupes pour l'imputer et le scaler\n",
    "    imputer_group = h5file.create_group('imputer')\n",
    "    scaler_group = h5file.create_group('scaler')\n",
    "    \n",
    "    # Ajouter les données sérialisées\n",
    "    with open(imputer_temp, 'rb') as f:\n",
    "        imputer_group.create_dataset('data', data=np.void(f.read()))\n",
    "    with open(scaler_temp, 'rb') as f:\n",
    "        scaler_group.create_dataset('data', data=np.void(f.read()))\n",
    "        \n",
    "    # Supprimer les fichiers temporaires\n",
    "    os.remove(imputer_temp)\n",
    "    os.remove(scaler_temp)\n",
    "    \n",
    "print(\"Préprocesseurs sauvegardés dans ../models/preprocessing.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefacf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour charger un modèle h5 selon son type\n",
    "def load_model_from_h5(file_path):\n",
    "    \"\"\"\n",
    "    Charge un modèle à partir d'un fichier h5\n",
    "    \"\"\"\n",
    "    # D'abord, déterminer le type de modèle à partir des métadonnées\n",
    "    metadata_path = file_path.replace('.h5', '_metadata.h5')\n",
    "    \n",
    "    with h5py.File(metadata_path, 'r') as h5file:\n",
    "        model_type = h5file.attrs['model_type']\n",
    "    \n",
    "    if model_type == 'LGBMClassifier':  # LightGBM models\n",
    "        model = lgb.Booster(model_file=file_path)\n",
    "        # Convertir le booster en LGBMClassifier\n",
    "        classifier = lgb.LGBMClassifier()\n",
    "        classifier._Booster = model\n",
    "        return classifier\n",
    "        \n",
    "    elif model_type == 'XGBClassifier':  # XGBoost models\n",
    "        model = XGBClassifier()\n",
    "        model.load_model(file_path)\n",
    "        return model\n",
    "        \n",
    "    else:  # Scikit-learn models (RandomForest, LogisticRegression, etc.)\n",
    "        # Charger le modèle depuis le format h5\n",
    "        with h5py.File(file_path, 'r') as h5file:\n",
    "            sklearn_group = h5file['sklearn_model']\n",
    "            model_dump = sklearn_group['model_dump'][()]\n",
    "            \n",
    "            # Écrire le dump dans un fichier temporaire\n",
    "            temp_file = tempfile.NamedTemporaryFile(delete=False).name\n",
    "            with open(temp_file, 'wb') as f:\n",
    "                f.write(model_dump.tobytes())\n",
    "                \n",
    "            # Charger le modèle depuis le fichier temporaire\n",
    "            with open(temp_file, 'rb') as f:\n",
    "                model = pickle.load(f)\n",
    "                \n",
    "            # Supprimer le fichier temporaire\n",
    "            os.remove(temp_file)\n",
    "            \n",
    "        return model\n",
    "\n",
    "# Test: chargement du modèle sauvegardé\n",
    "try:\n",
    "    loaded_model = load_model_from_h5(model_path)\n",
    "    print(f\"Modèle chargé avec succès : {type(loaded_model).__name__}\")\n",
    "    \n",
    "    # Vérifier que le modèle fonctionne correctement\n",
    "    sample_pred = loaded_model.predict_proba(X_validation_set[:5])[:, 1]\n",
    "    print(f\"Prédictions d'échantillon: {sample_pred}\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors du chargement du modèle: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efae2488",
   "metadata": {},
   "source": [
    "## Conclusion et prochaines étapes\n",
    "\n",
    "Dans ce notebook, nous avons:\n",
    "\n",
    "1. Exploré et préparé les données Home Credit pour la modélisation\n",
    "2. Créé de nouvelles caractéristiques via l'ingénierie des caractéristiques\n",
    "3. Entraîné et évalué plusieurs modèles de machine learning\n",
    "4. Comparé leurs performances et identifié le meilleur modèle\n",
    "\n",
    "### Observations clés\n",
    "\n",
    "- XGBoost et LightGBM ont généralement montré les meilleures performances\n",
    "- Les caractéristiques EXT_SOURCE sont parmi les plus importantes pour la prédiction\n",
    "- Notre modèle d'ensemble a amélioré légèrement les performances par rapport aux modèles individuels\n",
    "\n",
    "### Prochaines étapes\n",
    "\n",
    "1. **API REST** : Développer une API Flask pour servir notre meilleur modèle\n",
    "2. **Dashboard** : Créer un tableau de bord interactif avec Dash pour visualiser les prédictions et les explications\n",
    "3. **Optimisation** : Améliorer notre modèle en ajustant davantage les hyperparamètres et en intégrant plus de données\n",
    "4. **Interprétabilité** : Implémenter des méthodes comme SHAP pour expliquer les prédictions individuelles\n",
    "5. **Déploiement** : Mettre en place l'infrastructure pour déployer le modèle et le tableau de bord en production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35203ea5",
   "metadata": {},
   "source": [
    "### 2. Random Forest (Forêt aléatoire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94071718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle Random Forest\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=50, verbose=1, n_jobs=-1)\n",
    "random_forest.fit(X_training_set, y_training_set)\n",
    "\n",
    "# Prédictions sur l'ensemble de validation\n",
    "random_forest_pred = random_forest.predict(X_validation_set)\n",
    "random_forest_pred_proba = random_forest.predict_proba(X_validation_set)[:, 1]\n",
    "\n",
    "# Évaluation du modèle\n",
    "print(\"Random Forest - Rapport de classification:\")\n",
    "print(classification_report(y_validation_set, random_forest_pred))\n",
    "print(f\"AUC-ROC: {roc_auc_score(y_validation_set, random_forest_pred_proba):.4f}\")\n",
    "\n",
    "# Prédictions sur le nouveau jeu de test\n",
    "random_forest_new = random_forest.predict(new_test_transformed)\n",
    "print(\"\\nDistribution des prédictions sur le nouveau jeu de test:\")\n",
    "print(pd.Series(random_forest_new).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2d2f1d",
   "metadata": {},
   "source": [
    "## 7.1 Comparaison des performances avec le modèle LightGBM\n",
    "\n",
    "Comparons les performances de notre meilleur modèle avec le modèle LightGBM de référence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
